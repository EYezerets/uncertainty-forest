{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from uncertainty_forest.uncertainty_forest import UncertaintyForest\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import entropy, multivariate_normal\n",
    "from scipy.integrate import nquad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_eval(X, y, frac_eval):\n",
    "    \n",
    "    if frac_eval == 0:\n",
    "        return X, y, [], []\n",
    "    \n",
    "    n = len(y)\n",
    "    n_eval = int(np.floor(frac_eval*n))\n",
    "    eval_indices = np.random.choice(np.arange(n), size = n_eval, replace = False)\n",
    "    X_eval = X[eval_indices, :]\n",
    "    y_eval = y[eval_indices]\n",
    "    X = np.delete(X, eval_indices, axis = 0)\n",
    "    y = np.delete(y, eval_indices, axis = 0)\n",
    "    \n",
    "    return X, y, X_eval, y_eval\n",
    "\n",
    "def generate_data(n, d, mu = 1, var1 = 1, pi = 0.5, truncate = False, three_class = False):\n",
    "    \n",
    "    means, Sigma, probs = _make_params(d, mu = mu, var1 = var1, pi = pi, three_class = three_class)\n",
    "    counts = np.random.multinomial(n, probs, size = 1)[0]\n",
    "    \n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    for k in range(len(probs)):\n",
    "        X_data.append(np.random.multivariate_normal(means[k], Sigma, counts[k]))\n",
    "        y_data.append(np.repeat(2*k - 1, counts[k]))\n",
    "    X = np.concatenate(tuple(X_data))\n",
    "    y = np.concatenate(tuple(y_data))\n",
    "    \n",
    "    if truncate:\n",
    "        for i in range(n):\n",
    "            if X[i, 0] > 0:\n",
    "                y[i] = -1\n",
    "            elif X[i, 0] < 0:\n",
    "                y[i] = 1\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def _make_params(d, mu = 1, var1 = 1, pi = 0.5, three_class = False):\n",
    "    \n",
    "    if three_class:\n",
    "        return _make_three_class_params(n, d, mu)\n",
    "    \n",
    "    mean = np.zeros(d)\n",
    "    mean[0] = mu\n",
    "    means = [mean, -mean]\n",
    "    Sigma = np.eye(d)\n",
    "    Sigma[0, 0] = var1\n",
    "    probs = [pi, 1 - pi]\n",
    "    \n",
    "    return means, Sigma, probs\n",
    "\n",
    "def _make_three_class_params(n, d, mu):\n",
    "    \n",
    "    means = []\n",
    "    mean = np.zeros(d)\n",
    "    mean[d-1] = mu\n",
    "    means.append(copy.deepcopy(mean))\n",
    "    \n",
    "    mean[d-1] = 0\n",
    "    mean[0] = mu\n",
    "    means.append(copy.deepcopy(mean))\n",
    "    \n",
    "    mean[0] = -mu\n",
    "    means.append(copy.deepcopy(mean))\n",
    "                      \n",
    "    Sigma = np.eye(d)\n",
    "    probs = [1/3.]*3\n",
    "    \n",
    "    return means, Sigma, probs\n",
    "\n",
    "def split_by_class(X, y):\n",
    "    \n",
    "    classes, class_indices = np.unique(y, return_inverse = True)\n",
    "    K = len(classes)\n",
    "    X_by_class = []\n",
    "    y_by_class = []\n",
    "    \n",
    "    for k in range(K):\n",
    "        class_ = classes[k]\n",
    "        X_k = X[y == class_,:]\n",
    "        y_k = np.repeat(class_, X_k.shape[0])\n",
    "        X_by_class.append(X_k)\n",
    "        y_by_class.append(y_k)\n",
    "        \n",
    "    return X_by_class, y_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_norm_mutual_info(d, base = 2, mu = 1, var1 = 1, pi = 0.5, three_class = False, truncate = False):\n",
    "    \n",
    "    if truncate:\n",
    "        return 1.0, 1.0, 1.0 # TO DO: Compute entropy of X.\n",
    "    \n",
    "    # For the settings of interest, adding noise dimensions does not change the resulting mutual information.\n",
    "    if d > 1:\n",
    "        d = 2\n",
    "    \n",
    "    means, Sigma, probs = _make_params(d, mu = mu, var1 = var1, pi = pi, three_class = three_class)\n",
    "    \n",
    "    # Compute entropy and X and Y.\n",
    "    def func(*args):\n",
    "        x = np.array(args)\n",
    "        p = 0\n",
    "        for k in range(len(means)):\n",
    "            p += probs[k] * multivariate_normal.pdf(x, means[k], Sigma)\n",
    "        return -p * np.log(p) / np.log(base)\n",
    "\n",
    "    scale = 10\n",
    "    lims = [[-scale, scale]]*d\n",
    "    H_X, int_err = nquad(func, lims)\n",
    "    H_Y = entropy(probs, base = base)\n",
    "    \n",
    "    # Compute MI.\n",
    "    H_XY = (d * np.log(2*np.pi) + np.log(np.linalg.det(Sigma)) + d) / (2 * np.log(base))\n",
    "    I_XY = H_X - H_XY\n",
    "    \n",
    "    return I_XY, H_X, H_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info_distribution(n, d, frac_eval, algo, num_trials, setting, base = 2, parallel = False):\n",
    "    # For each trial, generate data and compute conditional entropy for each algorithm.\n",
    "    def worker(t):\n",
    "        X, y = generate_data(n, d, **kwargs)\n",
    "        X, y, X_eval, _ = split_train_eval(X, y, frac_eval)\n",
    "\n",
    "        # Estimate conditional probability of Y | X.\n",
    "        obj = algo['instance']\n",
    "        obj.fit(X, y)\n",
    "        return obj.estimate_mutual_info(X_eval)\n",
    "    \n",
    "    if parallel:\n",
    "        predicted_mutual_info = np.array(Parallel(n_jobs=-2)(delayed(worker)(t) for t in range(num_trials)))\n",
    "    else:\n",
    "        predicted_mutual_info = np.zeros(num_trials)\n",
    "        for t in tqdm_notebook(range(num_trials)):\n",
    "            predicted_mutual_info[t] = worker(t)\n",
    "            \n",
    "    return predicted_mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MI_by_algo_d(alpha, d, n, scale, frac_eval, algo, num_trials, setting, parallel, I_XY):\n",
    "    mi_est = np.mean(mutual_info_distribution(n, d, frac_eval, algo, num_trials, setting, parallel = parallel), axis = 0)\n",
    "    rel_err = np.abs(mi_est - I_XY) / I_XY\n",
    "    while rel_err > alpha:\n",
    "        return MI_by_algo_d(alpha, d, n*scale, scale, frac_eval, algo, num_trials, setting, parallel, I_XY)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of trials until with 5% of the true MI.\n",
    "def mutual_info_by_d(alpha, scale, ds, frac_eval, algos, num_trials, setting, base = 2, parallel = False):\n",
    "    \n",
    "    \n",
    "    # Repeat for all 'd', and save output in the 'algos' array.\n",
    "    num_sample_range = np.zeros((len(ds), len(algos)))\n",
    "    starting_n = 20\n",
    "    MI_by_algo = np.repeat(1000, len(algos))\n",
    "    \n",
    "    # Increase n until estimate is within 5% of the true I_XY.\n",
    "    for i in range(len(ds)):\n",
    "        I_XY = compute_norm_mutual_info(ds[i], **setting['kwargs'])\n",
    "        for j in range(len(algos)):\n",
    "            num_sample_range[i, j] = MI_by_algo_d(alpha, \n",
    "                                                  ds[i], \n",
    "                                                  starting_n, \n",
    "                                                  scale, \n",
    "                                                  frac_eval, \n",
    "                                                  algo, \n",
    "                                                  num_trials, \n",
    "                                                  setting,\n",
    "                                                  parallel, \n",
    "                                                  I_XY)\n",
    "                             \n",
    "    for j in range(len(algos)):\n",
    "        algos[j]['mi_by_d_%s' % setting['filename']] = num_sample_range[:, :, j]\n",
    "        \n",
    "    with open('algos_fig4.pkl', 'wb') as f:\n",
    "        pickle.dump(algos, f)\n",
    "    with open('ds_fig4.pkl', 'wb') as f:\n",
    "        pickle.dump(mus, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting figures.\n",
    "colors = [\"#d95f02\", \"#2166ac\", \"#c51b7d\"]\n",
    "settings = [\n",
    "    {\n",
    "        'name' : 'Sphereical Gaussians',\n",
    "        'kwargs': {},\n",
    "        'colors' : colors[1:3],\n",
    "        'filename' : 'spherical'\n",
    "    },\n",
    "    {\n",
    "        'name' : 'Elliptical Gaussians',\n",
    "        'kwargs': {'var1' : 3},\n",
    "        'colors' : colors[1:3],\n",
    "        'filename' : 'ellyptical'\n",
    "    },\n",
    "    {\n",
    "        'name' : 'Imbalanced Classes',\n",
    "        'kwargs': {'pi' : 0.8},\n",
    "        'colors' : colors[1:3],\n",
    "        'filename' : 'imbalanced'\n",
    "    },\n",
    "    {\n",
    "        'name' : 'Truncated Gaussians',\n",
    "        'kwargs': {'truncate' : True},\n",
    "        'colors' : colors[1:3],\n",
    "        'filename' : 'truncated'\n",
    "    },\n",
    "    {\n",
    "        'name' : 'Three Class Gaussians',\n",
    "        'kwargs': {'mu' : 3, 'three_class' : True},\n",
    "        'colors' : colors,\n",
    "        'filename' : 'three_class'\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data.\n",
    "n = 30\n",
    "num_trials = 4\n",
    "frac_eval = 0.3\n",
    "scale = 2\n",
    "alpha = 0.05\n",
    "ds = range(1, 10, 4)\n",
    "\n",
    "# Algorithms.\n",
    "algos = [\n",
    "#     {\n",
    "#         'instance': RandomForestClassifier(min_samples_leaf = 6, n_estimators = 30),\n",
    "#         'label': 'KSG',\n",
    "#         'title': 'KSG',\n",
    "#         'color': \"#1b9e77\",\n",
    "#     },\n",
    "    {\n",
    "        'instance': UncertaintyForest(finite_correction = False, min_samples_leaf = 6, n_estimators = 30),\n",
    "        'label': 'Mixed KSG',\n",
    "        'title': 'Mixed KSG',\n",
    "        'color': \"#fdae61\",\n",
    "    },\n",
    "    {\n",
    "        'instance': UncertaintyForest(min_samples_leaf = 6, n_estimators = 30),\n",
    "        'label': 'UF',\n",
    "        'title': 'Uncertainty Forest',\n",
    "        'color': \"#F41711\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Other.\n",
    "num_plotted_trials = 3\n",
    "parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7b7bacda9ffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msetting\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmutual_info_by_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrac_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-d1d055caf2e7>\u001b[0m in \u001b[0;36mmutual_info_by_d\u001b[0;34m(alpha, scale, ds, frac_eval, algos, num_trials, setting, base, parallel)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mI_XY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_norm_mutual_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kwargs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mnum_sample_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMI_by_algo_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrac_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI_XY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "for setting in settings:\n",
    "    mutual_info_by_d(alpha, scale, ds, frac_eval, algos, num_trials, setting, parallel = parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutual_info_by_d(ds, setting, algos, ax, alpha):\n",
    "    for algo in algos:\n",
    "        # Plot the mean over trials as a solid line.\n",
    "        ax.plot(ds, \n",
    "                algo['mi_by_d_%s' % setting['filename']], \n",
    "                label = algo['label'], \n",
    "                linewidth = 2, \n",
    "                color = algo['color'])\n",
    "\n",
    "    ax.set_xlabel(\"Number of Dimensions\")\n",
    "    ax.set_ylabel(\"Sample Size Until %f Convergence\" % alpha)\n",
    "    \n",
    "    ax.set_ylim(bottom = -0.05)\n",
    "    ax.set_ylim(top = 1.05)\n",
    "    ax.set_xlim(left = 0.05)\n",
    "    ax.set_xlim(right = 5.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fig4(ds, algos, axes, settings, alpha):\n",
    "    sns.set(font_scale = 1.4)\n",
    "    sns.set_style(\"ticks\")\n",
    "    plt.figure()\n",
    "    plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "    fig, axes = plt.subplots(len(settings), 1, figsize = (5,20))\n",
    "\n",
    "    for s in range(len(settings)):\n",
    "        plot_mutual_info_by_d(ds, setting, algos, axes[s], alpha)\n",
    "\n",
    "    plt.yticks(fontsize = 20)\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"fig4_d.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for setting in settings:\n",
    "    plot_mutual_info_by_d(ds, setting, algos, ax, alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
