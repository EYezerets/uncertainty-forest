{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from proglearn.forest import UncertaintyForest\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import entropy, norm\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uf(X, y, n_estimators = 300, max_samples = .4, base = np.exp(1), kappa = 3):\n",
    "    \n",
    "    # Build forest with default parameters.\n",
    "    model = BaggingClassifier(DecisionTreeClassifier(), \n",
    "                              n_estimators=n_estimators, \n",
    "                              max_samples=max_samples, \n",
    "                              bootstrap=False)\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    n = X.shape[0]\n",
    "    K = model.n_classes_\n",
    "    _, y = np.unique(y, return_inverse=True)\n",
    "    \n",
    "    # Find the indices of the training set used for partition.\n",
    "    sampled_indices = model.estimators_samples_[0]\n",
    "    unsampled_indices = np.delete(np.arange(0,n), sampled_indices)\n",
    "\n",
    "    # Randomly split the rest into voting and evaluation.\n",
    "    total_unsampled = len(unsampled_indices)\n",
    "    np.random.shuffle(unsampled_indices)\n",
    "    vote_indices = unsampled_indices[:total_unsampled//2]\n",
    "    eval_indices = unsampled_indices[total_unsampled//2:]\n",
    "    \n",
    "    cond_entropy = 0\n",
    "    for tree_idx, tree in enumerate(model):\n",
    "#         # Find the indices of the training set used for partition.\n",
    "#         sampled_indices = model.estimators_samples_[tree_idx]\n",
    "#         unsampled_indices = np.delete(np.arange(0,n), sampled_indices)\n",
    "        \n",
    "#         # Randomly split the rest into voting and evaluation.\n",
    "#         total_unsampled = len(unsampled_indices)\n",
    "#         np.random.shuffle(unsampled_indices)\n",
    "#         vote_indices = unsampled_indices[:total_unsampled//2]\n",
    "#         eval_indices = unsampled_indices[total_unsampled//2:]\n",
    "        \n",
    "        # Store the posterior in a num_nodes-by-num_classes matrix.\n",
    "        # Posteriors in non-leaf cells will be zero everywhere\n",
    "        # and later changed to uniform.\n",
    "        node_counts = tree.tree_.n_node_samples\n",
    "        class_counts = np.zeros((len(node_counts), K))\n",
    "        est_nodes = tree.apply(X[vote_indices])\n",
    "        est_classes = y[vote_indices]\n",
    "        for i in range(len(est_nodes)):\n",
    "            class_counts[est_nodes[i], est_classes[i]] += 1\n",
    "        \n",
    "        row_sums = class_counts.sum(axis=1) # Total number of estimation points in each leaf.\n",
    "        row_sums[row_sums == 0] = 1 # Avoid divide by zero.\n",
    "        class_probs = class_counts / row_sums[:, None]\n",
    "        \n",
    "        # Make the nodes that have no estimation indices uniform.\n",
    "        # This includes non-leaf nodes, but that will not affect the estimate.\n",
    "        class_probs[np.argwhere(class_probs.sum(axis = 1) == 0)] = [1 / K]*K\n",
    "        \n",
    "        # Apply finite sample correction and renormalize.\n",
    "        where_0 = np.argwhere(class_probs == 0)\n",
    "        for elem in where_0:\n",
    "            class_probs[elem[0], elem[1]] = 1 / (kappa*class_counts.sum(axis = 1)[elem[0]])\n",
    "        row_sums = class_probs.sum(axis=1)\n",
    "        class_probs = class_probs / row_sums[:, None]\n",
    "        \n",
    "        # Place evaluation points in their corresponding leaf node.\n",
    "        # Store evaluation posterior in a num_eval-by-num_class matrix.\n",
    "        eval_class_probs = class_probs[tree.apply(X[eval_indices])]\n",
    "        # eval_class_probs = [class_probs[x] for x in tree.apply(X[eval_indices])]\n",
    "        eval_entropies = [entropy(posterior) for posterior in eval_class_probs]\n",
    "        cond_entropy += np.mean(eval_entropies)\n",
    "      \n",
    "    return cond_entropy / n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CART_estimate(X, y, n_trees = 300, bootstrap = True):\n",
    "    model = RandomForestClassifier(bootstrap = bootstrap, n_estimators =n_trees)\n",
    "    model.fit(X, y)\n",
    "    class_counts = np.zeros((X.shape[0], model.n_classes_))\n",
    "    for tree_in_forest in model:\n",
    "        # get number of training elements in each partition\n",
    "        node_counts = tree_in_forest.tree_.n_node_samples\n",
    "        # get counts for all x (x.length array)\n",
    "        partition_counts = np.asarray([node_counts[x] for x in tree_in_forest.apply(X)])\n",
    "        # get class probability for all x (x.length, n_classes)\n",
    "        class_probs = tree_in_forest.predict_proba(X)\n",
    "        # get elements by performing row wise multiplication\n",
    "        elems = np.multiply(class_probs, partition_counts[:, np.newaxis])\n",
    "        # update counts for that tree\n",
    "        class_counts += elems\n",
    "    probs = class_counts/class_counts.sum(axis=1, keepdims=True)\n",
    "    entropies = -np.sum(np.log(probs)*probs, axis = 1)\n",
    "    # convert nan to 0\n",
    "    entropies = np.nan_to_num(entropies)\n",
    "    return np.mean(entropies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Data and Conditional Entropy Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n, d, mu = 1):\n",
    "    n_1 = np.random.binomial(n, .5) # number of class 1\n",
    "    mean = np.zeros(d)\n",
    "    mean[0] = mu\n",
    "    X_1 = np.random.multivariate_normal(mean, np.eye(d), n_1)\n",
    "    \n",
    "    X = np.concatenate((X_1, np.random.multivariate_normal(-mean, np.eye(d), n - n_1)))\n",
    "    y = np.concatenate((np.repeat(1, n_1), np.repeat(0, n - n_1)))\n",
    "  \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute True Conditional Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_cond_entropy(mu, base = np.exp(1)):\n",
    "    def func(x):\n",
    "        p = 0.5 * norm.pdf(x, mu, 1) + 0.5 * norm.pdf(x, -mu, 1)\n",
    "        return -p * np.log(p) / np.log(base)\n",
    "    \n",
    "    H_X = quad(func, -20, 20)\n",
    "    H_XY = 0.5*(1.0 + np.log(2 * np.pi)) / np.log(base)\n",
    "    H_Y = np.log(2.0) / np.log(base)\n",
    "    # I_XY = H_X - H_XY = H_Y - H_YX\n",
    "    return H_Y - H_X[0] + H_XY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Entropy versus Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_func(value, tick_number):\n",
    "    epsilon = 10 ** (-5)\n",
    "    if np.absolute(value) < epsilon:\n",
    "        return \"0\"\n",
    "    if np.absolute(value - 0.5) < epsilon:\n",
    "        return \"0.5\"\n",
    "    if np.absolute(value - 1) < epsilon:\n",
    "        return \"1\"\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cond_entropy_by_n(ax, num_plotted_trials, d, mu, algos, panel):\n",
    "        \n",
    "    sample_sizes = np.array(pickle.load(open('output/sample_sizes_d_%d.pkl' % d, 'rb')))\n",
    "    for j, algo in enumerate(algos):\n",
    "        result = pickle.load(open('output/%s_by_n_d_%d.pkl' % (algo['label'], d), 'rb'))\n",
    "        # Plot the mean over trials as a solid line.\n",
    "        ax.plot(sample_sizes,\n",
    "                np.mean(result, axis = 1).flatten(), \n",
    "                label = algo['label'], \n",
    "                linewidth = 4, \n",
    "                color = algo['color'])\n",
    "        # Use transparent lines to show other trials.\n",
    "        for t in range(num_plotted_trials):\n",
    "            ax.plot(sample_sizes, \n",
    "                    result[:, t].flatten(),  \n",
    "                    linewidth = 2, \n",
    "                    color = algo['color'],\n",
    "                    alpha = 0.15)\n",
    "    \n",
    "    truth = true_cond_entropy(mu)\n",
    "    ax.axhline(y = truth, linestyle = '-', color = \"black\", label = \"Truth\")\n",
    "        \n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(format_func))\n",
    "    ax.set_xlabel(\"Sample Size\")\n",
    "    ax.set_ylabel(\"Estimated Conditional Entropy\")\n",
    "    ax.set_title(\"%s) Effect Size = %.1f\" % (panel, mu))\n",
    "    ax.set_ylim(ymin = -0.05, ymax = 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Entropy Estimates versus Effect Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cond_entropy_by_mu(ax, d, n, algos, panel):\n",
    "    \n",
    "    mus = pickle.load(open('output/mus.pkl', 'rb'))\n",
    "    for j, algo in enumerate(algos):\n",
    "        result = pickle.load(open('output/%s_by_mu_d_%d.pkl' % (algo['label'], d), 'rb'))\n",
    "        # Plot the mean over trials as a solid line.\n",
    "        ax.plot(mus,\n",
    "                np.mean(result, axis = 1).flatten(), \n",
    "                label = algo['label'], \n",
    "                linewidth = 4, \n",
    "                color = algo['color'])\n",
    "    \n",
    "    truth = [true_cond_entropy(mu) for mu in mus]\n",
    "    ax.plot(mus, truth, label = 'Truth', linewidth = 4, color = 'black')\n",
    "\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(format_func))\n",
    "    ax.set_ylim(ymin = -.05)\n",
    "    ax.set_title(\"%s) n = %d\" % (panel, n))\n",
    "    ax.set_xlabel(\"Effect Size\")\n",
    "    ax.set_ylabel(\"Estimated Conditional Entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fig2(num_plotted_trials, d1, d2, n1, n2, effect_size, algos):\n",
    "    sns.set(font_scale = 3)\n",
    "    sns.set_style(\"ticks\")\n",
    "    plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "    plt.rcParams['figure.figsize'] = [30, 20]\n",
    "    fig, axes = plt.subplots(2, 2)\n",
    "    \n",
    "    plot_cond_entropy_by_n(axes[0, 0], num_plotted_trials, d1, effect_size, algos, \"A\")\n",
    "    plot_cond_entropy_by_mu(axes[0, 1], d1, n1, algos, \"B\")\n",
    "    \n",
    "    plot_cond_entropy_by_n(axes[1, 0], num_plotted_trials, d2, effect_size, algos, \"C\") \n",
    "    plot_cond_entropy_by_mu(axes[1, 1], d2, n2, algos, \"D\")\n",
    "    \n",
    "    axes[0,0].legend(loc = \"upper left\", prop={'size': 12})#edited font size to fit many lines\n",
    "    \n",
    "    fig.text(-0.05, 0.27, 'd = %d' % d2, ha='left', va='center', fontsize = 40)\n",
    "    fig.text(-0.05, 0.77, 'd = %d' % d1, ha='left', va='center', fontsize = 40)\n",
    "    \n",
    "    plt.subplots_adjust(left=-1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"fig2.pdf\", bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cond_entropy_vs_n(mean, d, num_trials, sample_sizes, algos):\n",
    "    \n",
    "    def worker(t):\n",
    "        X, y = generate_data(elem, d, mu = mean)\n",
    "        \n",
    "        ret = []\n",
    "        for algo in algos:\n",
    "            ret.append(estimate_ce(X, y, algo['label']))\n",
    "\n",
    "        return tuple(ret)\n",
    "    \n",
    "    output = np.zeros((len(algos), len(sample_sizes), num_trials))\n",
    "    for i, elem in enumerate(sample_sizes):\n",
    "        results = np.array(Parallel(n_jobs=-2)(delayed(worker)(t) for t in range(num_trials)))\n",
    "        for j in range(len(algos)):\n",
    "            output[j, i, :] = results[:, j]\n",
    "        \n",
    "    pickle.dump(sample_sizes, open('output/sample_sizes_d_%d.pkl' % d, 'wb'))\n",
    "    for j, algo in enumerate(algos):\n",
    "        pickle.dump(output[j], open('output/%s_by_n_d_%d.pkl' % (algo['label'], d), 'wb'))\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_ce(X, y, label):\n",
    "    if label == \"CART\":\n",
    "        return CART_estimate(X, y)\n",
    "    elif label == \"IRF\":\n",
    "        frac_eval = 0.3\n",
    "        irf = CalibratedClassifierCV(base_estimator=RandomForestClassifier(n_estimators = 300), \n",
    "                                     method='isotonic', \n",
    "                                     cv = 5)\n",
    "        # X_train, y_train, X_eval, y_eval = split_train_eval(X, y, frac_eval)\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        irf.fit(X_train, y_train)\n",
    "        p = irf.predict_proba(X_eval)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF\":\n",
    "        return uf(X, y, base = np.exp(1), kappa = 3)\n",
    "    elif label == \"UF2\":\n",
    "        frac_eval = 0.3\n",
    "        frac_vote = 0.3 / (1 - frac_eval) # 30% of the original data.\n",
    "        kappa = 3\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X_train, y_train)\n",
    "        p = uf2.predict_proba(X_eval)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF K=0.1\":\n",
    "        return uf(X, y, base = np.exp(1), kappa = 0.1)\n",
    "    elif label == \"UF K=0.3\":\n",
    "        return uf(X, y, base = np.exp(1), kappa = 0.3)\n",
    "    elif label == \"UF K=1\":\n",
    "        return uf(X, y, base = np.exp(1), kappa = 1)\n",
    "    elif label == \"UF K=3\":\n",
    "        return uf(X, y, base = np.exp(1), kappa = 3)\n",
    "    elif label == \"UF K=10\":\n",
    "        return uf(X, y, base = np.exp(1), kappa = 10)\n",
    "    elif label == \"UF2 K=0.1 frac_vote=0.3 evalsplit\":\n",
    "        frac_eval = 0.3\n",
    "        frac_vote = 0.3 / (1 - frac_eval) # 30% of the original data.\n",
    "        kappa = 0.1\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X_train, y_train)\n",
    "        p = uf2.predict_proba(X_eval)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=0.3 frac_vote=0.3 evalsplit\":\n",
    "        frac_eval = 0.3\n",
    "        frac_vote = 0.3 / (1 - frac_eval) # 30% of the original data.\n",
    "        kappa = 0.3\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X_train, y_train)\n",
    "        p = uf2.predict_proba(X_eval)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=1 frac_vote=0.3 evalsplit\":\n",
    "        frac_eval = 0.3\n",
    "        frac_vote = 0.3 / (1 - frac_eval) # 30% of the original data.\n",
    "        kappa = 1\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X_train, y_train)\n",
    "        p = uf2.predict_proba(X_eval)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=3 frac_vote=0.3 evalsplit\":\n",
    "        frac_eval = 0.3\n",
    "        frac_vote = 0.3 / (1 - frac_eval) # 30% of the original data.\n",
    "        kappa = 3\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X_train, y_train)\n",
    "        p = uf2.predict_proba(X_eval)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=10 frac_vote=0.3 evalsplit\":\n",
    "        frac_eval = 0.3\n",
    "        frac_vote = 0.3 / (1 - frac_eval) # 30% of the original data.\n",
    "        kappa = 10\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X_train, y_train)\n",
    "        p = uf2.predict_proba(X_eval)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=3 frac_vote=0.2 evalsplit\":\n",
    "        frac_eval = 0.3\n",
    "        frac_vote = 0.2 / (1 - frac_eval) # 30% of the original data.\n",
    "        kappa = 3\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X_train, y_train)\n",
    "        p = uf2.predict_proba(X_eval)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=3 frac_vote=0.4 evalsplit\":\n",
    "        frac_eval = 0.3\n",
    "        frac_vote = 0.4 / (1 - frac_eval) # 30% of the original data.\n",
    "        kappa = 3\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X_train, y_train)\n",
    "        p = uf2.predict_proba(X_eval)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=3 frac_vote=0.5 evalsplit\":\n",
    "        frac_eval = 0.3\n",
    "        frac_vote = 0.5 / (1 - frac_eval) # 30% of the original data.\n",
    "        kappa = 3\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X_train, y_train)\n",
    "        p = uf2.predict_proba(X_eval)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=10 frac_vote=0.2 evalsplit\":\n",
    "        frac_eval = 0.3\n",
    "        frac_vote = 0.2 / (1 - frac_eval) # 30% of the original data.\n",
    "        kappa = 10\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X_train, y_train)\n",
    "        p = uf2.predict_proba(X_eval)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=10 frac_vote=0.4 evalsplit\":\n",
    "        frac_eval = 0.3\n",
    "        frac_vote = 0.4 / (1 - frac_eval) # 30% of the original data.\n",
    "        kappa = 10\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X_train, y_train)\n",
    "        p = uf2.predict_proba(X_eval)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=10 frac_vote=0.5 evalsplit\":\n",
    "        frac_eval = 0.3\n",
    "        frac_vote = 0.5 / (1 - frac_eval) # 30% of the original data.\n",
    "        kappa = 10\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X_train, y_train)\n",
    "        p = uf2.predict_proba(X_eval)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=0.1 frac_vote=0.3 eval_notsplit\":\n",
    "#         frac_eval = 0.0 # not 0.3\n",
    "        frac_vote = 0.3 # 30% of the total data.\n",
    "        kappa = 0.1\n",
    "#         X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X, y)\n",
    "        p = uf2.predict_proba(X) # not X_eval\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=0.3 frac_vote=0.3 eval_notsplit\":\n",
    "#         frac_eval = 0.0\n",
    "        frac_vote = 0.3 # 30% of the total data.\n",
    "        kappa = 0.3\n",
    "#         X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X, y)\n",
    "        p = uf2.predict_proba(X) \n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=1 frac_vote=0.3 eval_notsplit\":\n",
    "#         frac_eval = 0.0\n",
    "        frac_vote = 0.3 # 30% of the total data.\n",
    "        kappa = 1\n",
    "#         X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X,y)\n",
    "        p = uf2.predict_proba(X)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=3 frac_vote=0.3 eval_notsplit\":\n",
    "#         frac_eval = 0.0\n",
    "        frac_vote = 0.3 # 30% of the total data.\n",
    "        kappa = 3\n",
    "#         X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X, y)\n",
    "        p = uf2.predict_proba(X)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=10 frac_vote=0.3 eval_notsplit\":\n",
    "#         frac_eval = 0.0\n",
    "        frac_vote = 0.3 # 30% of the total data.\n",
    "        kappa = 10\n",
    "#         X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X, y)\n",
    "        p = uf2.predict_proba(X)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=10 frac_vote=0.2 eval_notsplit\":\n",
    "#         frac_eval = 0.0\n",
    "        frac_vote = 0.2 # 30% of the total data.\n",
    "        kappa = 10\n",
    "#         X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X, y)\n",
    "        p = uf2.predict_proba(X)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=10 frac_vote=0.4 eval_notsplit\":\n",
    "#         frac_eval = 0.0\n",
    "        frac_vote = 0.4 # 30% of the total data.\n",
    "        kappa = 10\n",
    "#         X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X, y)\n",
    "        p = uf2.predict_proba(X)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    elif label == \"UF2 K=10 frac_vote=0.5 eval_notsplit\":\n",
    "#         frac_eval = 0.0\n",
    "        frac_vote = 0.5 # 30% of the total data.\n",
    "        kappa = 10\n",
    "#         X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        uf2 = UncertaintyForest(n_estimators = 300, kappa = kappa, frac_vote = frac_vote) #changed to match UF\n",
    "        uf2.fit(X, y)\n",
    "        p = uf2.predict_proba(X)\n",
    "        return np.mean(entropy(p.T, base = np.exp(1)))\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unrecognized Label!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cond_entropy_vs_mu(n, d, num_trials, mus, algos):\n",
    "    \n",
    "    def worker(t):\n",
    "        X, y = generate_data(n, d, mu = elem)\n",
    "        \n",
    "        ret = []\n",
    "        for algo in algos:\n",
    "            ret.append(estimate_ce(X, y, algo['label']))\n",
    "\n",
    "        return tuple(ret)\n",
    "    \n",
    "    output = np.zeros((len(algos), len(mus), num_trials))\n",
    "    for i, elem in enumerate(mus):\n",
    "        results = np.array(Parallel(n_jobs=-2)(delayed(worker)(t) for t in range(num_trials)))\n",
    "        for j in range(len(algos)):\n",
    "            output[j, i, :] = results[:, j]\n",
    "    \n",
    "    pickle.dump(mus, open('output/mus.pkl', 'wb'))\n",
    "    for j, algo in enumerate(algos):\n",
    "        pickle.dump(output[j], open('output/%s_by_mu_d_%d.pkl' % (algo['label'], d), 'wb'))\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data.\n",
    "# mus = [i * 0.5 for i in range(1, 11)]\n",
    "# effect_size = 1\n",
    "# d1 = 1\n",
    "# d2 = 20\n",
    "# n1 = 3000\n",
    "# n2 = 6000\n",
    "# num_trials = 50 # 20\n",
    "# num_plotted_trials = 10\n",
    "# sample_sizes_d1 = range(300, 1201, 90)\n",
    "# sample_sizes_d2 = range(500, 3001, 250)\n",
    "\n",
    "# Fake params.\n",
    "mus = [i * 0.5 for i in range(1, 3)]\n",
    "effect_size = 1\n",
    "d1 = 1\n",
    "d2 = 3\n",
    "n1 = 100\n",
    "n2 = 110\n",
    "num_trials = 2\n",
    "num_plotted_trials = 2\n",
    "sample_sizes_d1 = range(100, 120, 10)\n",
    "sample_sizes_d2 = range(100, 130, 10)\n",
    "\n",
    "# Algorithms.\n",
    "algos = [\n",
    "#     {\n",
    "#         'label': 'CART',\n",
    "#         'title': 'CART Forest',\n",
    "#         'color': \"#1b9e77\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'IRF',\n",
    "#         'title': 'Isotonic Reg. Forest',\n",
    "#         'color': \"#fdae61\",\n",
    "#     },\n",
    "    {\n",
    "        'label': 'UF',\n",
    "        'title': 'Uncertainty Forest',\n",
    "        'color': \"#F41711\",\n",
    "    },\n",
    "    {\n",
    "        'label': 'UF2',\n",
    "        'title': 'Uncertainty Forest 2',\n",
    "        'color': \"#0000FF\",\n",
    "    }\n",
    "#     {\n",
    "#         'label': 'UF K=0.1',\n",
    "#         'title': 'Uncertainty Forest',\n",
    "#         'color': \"#F41711\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF K=0.3',\n",
    "#         'title': 'Uncertainty Forest',\n",
    "#         'color': \"#FF9A33\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF K=1',\n",
    "#         'title': 'Uncertainty Forest',\n",
    "#         'color': \"#FFD533\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF K=3',\n",
    "#         'title': 'Uncertainty Forest',\n",
    "#         'color': \"#F9FF33\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF K=10',\n",
    "#         'title': 'Uncertainty Forest',\n",
    "#         'color': \"#90FF33\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=0.1 frac_vote=0.3 evalsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#33FFF8\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=0.3 frac_vote=0.3 evalsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#33A4FF\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=1 frac_vote=0.3 evalsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#3B33FF\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=3 frac_vote=0.3 evalsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#B433FF\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=10 frac_vote=0.3 evalsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#FF33D5\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=3 frac_vote=0.2 evalsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#33A4FF\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=3 frac_vote=0.3 evalsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#3B33FF\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=3 frac_vote=0.4 evalsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#B433FF\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=3 frac_vote=0.5 evalsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#FF33D5\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=10 frac_vote=0.2 evalsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#33A4FF\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=10 frac_vote=0.3 evalsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#3B33FF\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=10 frac_vote=0.4 evalsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#B433FF\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=10 frac_vote=0.5 evalsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#FF33D5\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=0.1 frac_vote=0.3 eval_notsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#33FFF8\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=0.3 frac_vote=0.3 eval_notsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#33A4FF\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=1 frac_vote=0.3 eval_notsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#3B33FF\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=3 frac_vote=0.3 eval_notsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#B433FF\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=10 frac_vote=0.3 eval_notsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#FF33D5\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=10 frac_vote=0.2 eval_notsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#33A4FF\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=10 frac_vote=0.4 eval_notsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#B433FF\",\n",
    "#     },\n",
    "#     {\n",
    "#         'label': 'UF2 K=10 frac_vote=0.5 eval_notsplit',\n",
    "#         'title': 'Uncertainty Forest 2',\n",
    "#         'color': \"#3B33FF\",\n",
    "#     },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated H(Y | X) versus n, d = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'tree_idx' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/eyezerets/uf/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/home/eyezerets/uf/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/eyezerets/uf/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/eyezerets/uf/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/eyezerets/uf/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"<ipython-input-10-1107e0ea7135>\", line 8, in worker\n  File \"<ipython-input-11-926625090b44>\", line 15, in estimate_ce\n  File \"<ipython-input-2-a87994018712>\", line 15, in uf\nUnboundLocalError: local variable 'tree_idx' referenced before assignment\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8cd6d4389368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_cond_entropy_vs_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meffect_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_sizes_d1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-1107e0ea7135>\u001b[0m in \u001b[0;36mget_cond_entropy_vs_n\u001b[0;34m(mean, d, num_trials, sample_sizes, algos)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uf/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uf/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uf/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'tree_idx' referenced before assignment"
     ]
    }
   ],
   "source": [
    "get_cond_entropy_vs_n(effect_size, d1, num_trials, sample_sizes_d1, algos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated H(Y | X) versus mu, d = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate conditional entropy vs mu.\n",
    "get_cond_entropy_vs_mu(n1, d1, num_trials, mus, algos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated H(Y | X) versus n, d = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate conditional entropy vs n.\n",
    "get_cond_entropy_vs_n(effect_size, d2, num_trials, sample_sizes_d2, algos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated H(Y | X) versus mu, d = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate conditional entropy vs mu.\n",
    "get_cond_entropy_vs_mu(n2, d2, num_trials, mus, algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fig2(num_plotted_trials, d1, d2, n1, n2, effect_size, algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
