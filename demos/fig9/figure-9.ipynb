{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from uncertainty_forest.uncertainty_forest import UncertaintyForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import entropy\n",
    "from scipy.integrate import nquad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "import mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronak/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble.forest import _generate_unsampled_indices\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cef_estimate_mike_1(X, y, n_estimators = 200, max_samples = .32, bootstrap = True, depth = 30, min_samples_leaf = 1, max_features = 1.):\n",
    "    model = BaggingClassifier(DecisionTreeClassifier(max_depth = depth, min_samples_leaf = min_samples_leaf, max_features = math.ceil(int(math.sqrt(X.shape[1])))), \n",
    "                              n_estimators = n_estimators, \n",
    "                              max_samples= max_samples, \n",
    "                              bootstrap = bootstrap)\n",
    "    model.fit(X, y)\n",
    "    class_counts = np.zeros((X.shape[0], model.n_classes_))\n",
    "    tree_idx = 0\n",
    "    for tree in model:\n",
    "        \n",
    "        # get out of bag indices.       \n",
    "        # Here's where we obtain unsampled indices.\n",
    "        # unsampled_indices = _generate_unsampled_indices(tree.random_state, len(X), int((1 - max_samples)*len(X)))\n",
    "        sampled_indices = model.estimators_samples_[tree_idx]\n",
    "        unsampled_indices = np.delete(np.arange(0,X.shape[0]), sampled_indices)\n",
    "        tree_idx = tree_idx + 1\n",
    "        # Done with unsampled indices.\n",
    "        \n",
    "        total_unsampled = len(unsampled_indices)\n",
    "        np.random.shuffle(unsampled_indices)\n",
    "        prob_indices, eval_indices = unsampled_indices[:total_unsampled//2], unsampled_indices[total_unsampled//2:]\n",
    "        # get all node counts\n",
    "        node_counts = tree.tree_.n_node_samples\n",
    "        # get probs for eval samples\n",
    "        posterior_class_counts = np.zeros((len(node_counts), model.n_classes_))\n",
    "        for prob_index in prob_indices:\n",
    "            posterior_class_counts[tree.apply(X[prob_index].reshape(1, -1)).item(), y[prob_index]] += 1\n",
    "        row_sums = posterior_class_counts.sum(axis=1)\n",
    "        row_sums[row_sums == 0] = 1\n",
    "        class_probs = (posterior_class_counts/row_sums[:, None])\n",
    "        \n",
    "        where_0 = np.argwhere(class_probs == 0)\n",
    "        for elem in where_0:\n",
    "            class_probs[elem[0], elem[1]] = 1/(2*row_sums[elem[0], None])\n",
    "        where_1 = np.argwhere(class_probs == 1)\n",
    "        for elem in where_1:\n",
    "            class_probs[elem[0], elem[1]] = 1 - 1/(2*row_sums[elem[0], None])\n",
    "        \n",
    "        class_probs.tolist()\n",
    "        partition_counts = np.asarray([node_counts[x] for x in tree.apply(X[eval_indices])])\n",
    "        # get probability for out of bag samples\n",
    "        eval_class_probs = [class_probs[x] for x in tree.apply(X[eval_indices])]\n",
    "        eval_class_probs = np.array(eval_class_probs)\n",
    "        # find total elements for out of bag samples\n",
    "        elems = np.multiply(eval_class_probs, partition_counts[:, np.newaxis])\n",
    "        # store counts for each x (repeat fhis for each tree)\n",
    "        class_counts[eval_indices] += elems\n",
    "    # calculate p(y|X = x) for all x's\n",
    "    probs = class_counts/class_counts.sum(axis = 1, keepdims = True)\n",
    "    entropies = -np.sum(np.log(probs)*probs, axis = 1)\n",
    "    # convert nan to 0\n",
    "    entropies = np.nan_to_num(entropies)\n",
    "    return np.mean(entropies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n, d, K):\n",
    "    X = np.random.uniform(0, 1, size = (n, d))\n",
    "    y = np.random.randint(low=0, high=K, size=n)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_mi(X, y, label):\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    est_H_Y = entropy(counts, base=np.exp(1))\n",
    "    \n",
    "    if label == \"IRF\":\n",
    "        frac_eval = 0.3\n",
    "        irf = CalibratedClassifierCV(base_estimator=RandomForestClassifier(n_estimators = 300), \n",
    "                                     method='isotonic', \n",
    "                                     cv = 5)\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=frac_eval)\n",
    "        irf.fit(X_train, y_train)\n",
    "        p = irf.predict_proba(X_eval)\n",
    "        \n",
    "        return (est_H_Y - np.mean(entropy(p.T, base = np.exp(1))))\n",
    "    elif label == \"UF\":\n",
    "        return (est_H_Y - cef_estimate_mike_1(np.array(X), y, 300, .32, depth = 30))\n",
    "    elif label == \"KSG\":\n",
    "        return mixed.KSG(X, y.reshape(-1, 1))\n",
    "    elif label == \"Mixed KSG\":\n",
    "        return mixed.Mixed_KSG(X, y.reshape(-1, 1))\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognized Label!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutual_info(elems, over, algos, n = 10, d = 2, K = 3):\n",
    "    \n",
    "    for j, algo in enumerate(algos):\n",
    "        times = []\n",
    "        for i, elem in enumerate(elems):\n",
    "            \n",
    "            # Generate data with the proper n, d, and K.\n",
    "            if over == 'n':\n",
    "                X, y = generate_data(elem, d, K)\n",
    "            elif over == 'd':\n",
    "                X, y = generate_data(n, elem, K)\n",
    "            elif over == 'K':\n",
    "                X, y = generate_data(n, d, elem)\n",
    "            else:\n",
    "                raise ValueError(\"Must compute over 'n', 'd', or 'K'.\")\n",
    "\n",
    "            # Compute time for algo for this setting.\n",
    "            time = %timeit -n 1 -r 3 -q -o estimate_mi(X, y, algo['label'])\n",
    "            times.append(np.mean(time.timings))\n",
    "            \n",
    "        output = np.array(times)\n",
    "        if over == 'n':\n",
    "            pickle.dump(elems, open('ns.pkl', 'wb'))\n",
    "            pickle.dump(output, open('%s_by_n_d_%d_K_%d.pkl' % (algo['label'], d, K), 'wb'))\n",
    "        elif over == 'd':\n",
    "            pickle.dump(elems, open('ds.pkl', 'wb'))\n",
    "            pickle.dump(output, open('%s_by_d_n_%d_K_%d.pkl' % (algo['label'], n, K), 'wb'))\n",
    "        elif over == 'K':\n",
    "            pickle.dump(elems, open('Ks.pkl', 'wb'))\n",
    "            pickle.dump(output, open('%s_by_K_n_%d_d_%d.pkl' % (algo['label'], n, d), 'wb'))\n",
    "        else:\n",
    "            raise ValueError(\"Must compute over 'n', 'd', or 'K'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real params\n",
    "ns = [\n",
    "    200,\n",
    "    500,\n",
    "    1000,\n",
    "    2000,\n",
    "    5000,\n",
    "    10000\n",
    "]\n",
    "ds = range(2, 41, 2)\n",
    "Ks = range(2, 10, 1)\n",
    "n = 5000\n",
    "d = 4\n",
    "K = 3\n",
    "\n",
    "# Fake params\n",
    "# ns = range(200, 301, 50)\n",
    "# ds = range(2, 5, 1)\n",
    "# Ks = range(2, 5, 1)\n",
    "# n = 200\n",
    "# d = 2\n",
    "# K = 2\n",
    "\n",
    "# Algorithms.\n",
    "algos = [\n",
    "    {\n",
    "        'label': 'IRF',\n",
    "        'title': 'Isotonic Reg. Forest',\n",
    "        'color': \"#fdae61\",\n",
    "    },\n",
    "    {\n",
    "        'label': 'KSG',\n",
    "        'title': 'KSG',\n",
    "        'color': \"#1b9e77\",\n",
    "    },\n",
    "    {\n",
    "        'label': 'Mixed KSG',\n",
    "        'title': 'Mixed KSG',\n",
    "        'color': \"purple\",\n",
    "    },\n",
    "    {\n",
    "        'label': 'UF',\n",
    "        'title': 'Uncertainty Forest',\n",
    "        'color': \"#F41711\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mutual_info(ns, 'n', algos, d = d, K = K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mutual_info(ds, 'd', algos, n = n, K = K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mutual_info(Ks, 'K', algos, n = n, d = d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
